{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence across model hyper-parameters\n",
    "\n",
    "This script is used to generate a plot of model coherence metrics for a particular model hyper-parameter. The most obvious use of this is for the number of topics.\n",
    "\n",
    "This script generates figure 1 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loads individual processed tweets, removes required tokens, and creates a corpus for all tweets\n",
    "#IMPORTS\n",
    "from os import listdir\n",
    "import json\n",
    "import logging\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#This path should contain processed tweets\n",
    "path = ''\n",
    "tweets = []\n",
    "stops = set(stopwords.words('dutch'))\n",
    "\n",
    "for month in ['08', '09', '10', '11', '12', '01', '02', '03', '04', '05', '06', '07']: #controls for month \n",
    "    for file in listdir(path):\n",
    "        if file.split('_')[0] == month:   \n",
    "            with open(path + '/' + file, 'r') as infile:\n",
    "                data = json.loads(infile.read())\n",
    "                for identifier in data.keys():\n",
    "                    tweet = []\n",
    "                    for token in range(len(data[identifier]['full_frog'])):\n",
    "                        #punctuation removal\n",
    "                        if data[identifier]['full_frog'][token]['dep'] != 'punct':\n",
    "                            #stopword removal\n",
    "                            if data[identifier]['full_frog'][token]['lemma'] not in stops:\n",
    "                                #lowercasing the entire token\n",
    "                                tweet.append(data[identifier]['full_frog'][token]['lemma'].lower())\n",
    "                    tweets.append(tweet)\n",
    "\n",
    "#converting the tweets into format gensim works with\n",
    "dictionary = corpora.Dictionary(tweets)\n",
    "corpus = [dictionary.doc2bow(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This computes the actual coherence metrics\n",
    "#IMPORTS\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "import datetime\n",
    "import logging\n",
    "import json\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#This is a list of values to test, the script is set up for topic numbers\n",
    "numbers = []\n",
    "                     \n",
    "#Models\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "for number in numbers:\n",
    "    print('Starting for '+ str(number) +' topics')\n",
    "    \n",
    "    #This trains the moidel itself, here training parameters can be adjusted to balance speed and sufficient training.\n",
    "    #It might also be desirable to control for randomness by assigning a constant random seed.\n",
    "    #If training for something else than topic number assign 'number' to a different paramater\n",
    "    lda = LdaModel(corpus, num_topics=number, id2word=dictionary, alpha='auto', eta='auto',\n",
    "                   passes=1, iterations=100000000, gamma_threshold=0.001, chunksize=25000)\n",
    "    \n",
    "    #This determines where model files get saved (useful for manual inspection)\n",
    "    temp_file = r\"path\" + str(number)\n",
    "    lda.save(temp_file)\n",
    "    \n",
    "    #This computes all four coherence metrics available in gensim - some of these can be removed to speed up computation\n",
    "    time = datetime.datetime.now().strftime(\"%I:%M\")\n",
    "    print(time +\"   Starting u_mass\")\n",
    "    cm = CoherenceModel(model=lda, corpus=corpus, coherence='u_mass')\n",
    "    u_mass = cm.get_coherence()\n",
    "      \n",
    "    time = datetime.datetime.now().strftime(\"%I:%M\")\n",
    "    print(time +\"   Starting c_v\")\n",
    "    cm = CoherenceModel(model=lda, texts=tweets, coherence='c_v')\n",
    "    c_v = cm.get_coherence()\n",
    "       \n",
    "    time = datetime.datetime.now().strftime(\"%I:%M\")\n",
    "    print(time +\"   Starting c_uci\")\n",
    "    cm = CoherenceModel(model=lda, texts=tweets, coherence='c_uci')\n",
    "    c_uci = cm.get_coherence()\n",
    "      \n",
    "    time = datetime.datetime.now().strftime(\"%I:%M\")\n",
    "    print(time +\"   Starting c_npmi\")\n",
    "    cm = CoherenceModel(model=lda, texts=tweets, coherence='c_npmi')\n",
    "    c_npmi = cm.get_coherence()\n",
    "       \n",
    "    coherences = {'u_mass': u_mass,\n",
    "                 'c_v': c_v,\n",
    "                 'c_uci': c_v,\n",
    "                 'c_npmi': c_npmi}\n",
    "    \n",
    "    #This saves the coherence metrics in a simple .txt\n",
    "    #Adjust the path as needed\n",
    "    with open(r'path', 'a+') as outfile:\n",
    "        json.dump({number: coherences}, outfile)\n",
    "    \n",
    "    print('Finished for '+ str(number) +' topics')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This plots the coherence metrics\n",
    "#IMPORTS\n",
    "import json \n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.pyplot import savefig\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "coherence = {}\n",
    "\n",
    "#path corresponding to where the coherence .txt is located\n",
    "with open(r'path', 'r') as infile:\n",
    "    for line in infile:\n",
    "        coherence.update(json.loads(line))\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for metric in ['u_mass', 'c_v', 'c_uci', 'c_npmi']:\n",
    "    dicti = {}\n",
    "    for topics in coherence.keys():\n",
    "        dicti[int(topics)] = coherence[topics][metric]\n",
    "    \n",
    "    tuples = sorted(dicti.items())\n",
    "    x, y = zip(*tuples) # unpack a list of pairs into two tuples\n",
    "    y = preprocessing.scale(y)   \n",
    "    plt.plot(x, y, label = metric)\n",
    "    \n",
    "plt.xlabel('Number of topics', fontsize = 15)\n",
    "plt.ylabel('Coherence (rescaled)', fontsize = 15)\n",
    "plt.legend(prop={'size':20}) \n",
    "savefig(r'PATH')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
